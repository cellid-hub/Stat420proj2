---
title: "MLEs: Variance, Bias, and Risk"
author: "Nathan Poteet, Dylan Celli, Matthew Foulk"
output:
  pdf_document:
    toc: yes
  html_document:
    number_sections: yes    
    toc: yes
editor_options: 
  markdown: 
    wrap: 72
---

# Population Distribution: $N(\mu, \sigma^2)$ and $\theta = \mu^2$

Consider the following three estimators for $\mu^2$
$$ \hat{\theta}_1= \overline{X}^2$$
$$\hat{\theta}_2 = \overline{X}^2 - \frac{\sigma^2}{n}$$

$$\hat{\theta}_3 = \overline{X}^2 - \frac{S^2}{n}$$
$$ \hat{\theta}_4 = \overline{X}^2 - \frac{\left(\frac{n-1}{n}\right)S^2}{n}$$
Note that $\hat{\theta}_2$ is the mle, $\hat{\theta}_2$,
$\hat{\theta}_3$ are unbiased estimators, and $\hat{\theta}_4$ is
constructed using MLEs for both $\mu^2$ and $\sigma^2$.

Suppose we are sampling from $N(\mu = 10, \sigma^2=4)$. Define four
functions that take an input $n$ for the sample size: inside the
function, you get a sample of size $n$ coming from
$N(\mu = 10, \sigma^2=4)$, and output the value of each of the four
estimators above on this sample.

```{r}
#Theta in each case is an estimator for mu^2
theta1 <-function(n) {
  theta <- mean(rnorm(n,mean = 10, sd = 2))^2
}
theta2 <-function(n) {
  theta <- theta1(n)- 4/n
}
theta3 <-function(n) {
  norm_data <- rnorm(n,mean = 10, sd = 2)
  theta <- mean(norm_data)^2- var(norm_data)/n
}
theta4 <-function(n) {
  norm_data <- rnorm(n,mean = 10, sd = 2)
  theta <- mean(norm_data)^2 - (((n-1)/n)*var(norm_data))/n
}

```

## Mean Squared Errors

Calculate the empirical variance, bias, and mean squared error, of the
three estimators, when working with samples of size 8. (Use the
'replicate' function to get 100000 replicates of the three estimators
when working with a sample of size 8, then calculate the mean, var,
mean-10)

```{r}
empirical_results = list()

#Theta1
empirical_results <- append(empirical_results, 
                            list(replicate(100000,theta1(8))))
#theta2
empirical_results <- append(empirical_results, 
                            list(replicate(100000,theta2(8))))
#theta3
empirical_results <- append(empirical_results, 
                            list(replicate(100000,theta3(8))))
#theta4
empirical_results <- append(empirical_results, 
                            list(replicate(100000,theta4(8))))

for (i in c(1,2,3,4)){
  mean <- mean(empirical_results[[i]])
  variance <- var(empirical_results[[i]])
  bias <- (mean - 10)#^2 Do we need to square the bias here?
  
  print("======================")
  print(paste("Theta",i))
  print(paste("Mean: ", mean))
  print(paste("Variance: ", variance))
  print(paste("Bias: ", bias ))
}
```

Verify that
$$ \text{MSE}_{\text{emp}} \thickapprox \text{Var}_{\text{emp}} + (\text{Bias}_\text{emp})^2$$

It is possible to calculate the exact theoretical MSE of the four
estimators defined above as functions of $\mu$, $\sigma^2$ and $n$.

Write four functions that calculate the MSE's of the given estimators
taking input $\mu$, $\sigma^2$, and $n$.

```{r}
MSE1 <-function(mu,variance,n) {
  MSE <- (4*variance*mu^2)/n + 3*variance^2/n^2
}
MSE2 <-function(mu,variance,n) {
  MSE <- (4*variance*mu^2)/n + (2*variance^2)/n^2
}
MSE3 <-function(mu,variance,n) {
  MSE <- (4*variance*mu^2)/n + (2*variance^2)/n^2 + (2*variance^2)/(n^2*(n-1))
}
MSE4 <-function(mu,variance,n) {
  MSE <- (variance^4/n^2)*(-1/n^2 + 2/n + 2) + (4*variance*mu^2)/n
}
```

For fixed value of $n=8$ and $\sigma^2 = 4$, and for different values of
$\mu^2 \in [70, 140]$, plot the graphs for the four mean square error
functions in a single plot. That is plot MSE vs $\mu^2$.

```{r}
x <- seq(70, 140, length.out = 1000)

y_1 <- MSE1(mu = sqrt(x), variance = 4, n=8)
y_2 <- MSE2(mu = sqrt(x), variance = 4, n=8)
y_3 <- MSE3(mu = sqrt(x), variance = 4, n=8)
y_4 <- MSE4(mu = sqrt(x), variance = 4, n=8)

plot(x, y_1, type = 'l')
lines(x,y_2, col ='red' )
lines(x,y_3, col ='blue' )
lines(x,y_4, col ='green' )
```

For fixed value of $\mu=10$ and $\sigma^2 = 4$, and for different va
lues of $n \in \{1, 2, 3, 4, \dots 200\}$, plot the graphs for the four
mean square error functions in a single plot. That is plot MSE vs $n$
(the sample size).

```{r}
x <- seq(1, 200, length.out = 1000)

y_1 <- MSE1(mu = 10, variance = 4, n=x)
y_2 <- MSE2(mu = 10, variance = 4, n=x)
y_3 <- MSE3(mu = 10, variance = 4, n=x)
y_4 <- MSE4(mu = 10, variance = 4, n=x)

plot(x, y_1, type = 'l')
lines(x,y_2, col ='red' )
lines(x,y_3, col ='blue' )
lines(x,y_4, col ='green' )
```

What can you conclude?

Based on these plots, I can conclude that as the population mean
increases the MSE increases with it linearly, and that as the sample
size increases the MSE decreases as a function of a power of 1/n.

## Fisher Information, Efficiency, Asymptotic Calculations

For a given value of $\mu$ write the function that calculates the Fisher
Information $I(\mu^2)$ (this was calculated in the HW).

```{r}
fisher_mu_squared <- function(mu, variance){
  return(1/(4*mu^2*variance^2))
}

```

The MLE for $\mu^2$ is $\hat{\theta} = \overline{X}^2$. Empirically
verify that the asymptotic distribution of
$$\sqrt{n}(\hat{\theta} - \mu^2) \longrightarrow N(0, \frac{1}{I(\mu^2)})$$.

```{r}
#TODO
```

An unbiased estimator for $\mu^2$ is
$$\hat{\theta}_{u} = \overline{X}^2 - \frac{S^2}{n}$$. Write a function
that takes input $\mu, \sigma^2, n$ and outputs the efficiency of
$\hat{\theta}_{u}$.

```{r}
efficiency <- function(mu, variance, n){
  return((2*n*mu^2)/(2*n*mu^2 + variance))
}
```

For fixed value of $n=8$ and $\sigma^2 = 4$, and for different values of
$\mu^2 \in [70, 140]$, plot the graph of the efficiency of
$\hat{\theta}_\text{u}$. Thats is plot effiency vs $\mu^2$.

```{r}
n = 8
variance = 4
mus_squared = seq(70, 140, length.out = 1000)
effs = vector()
for (mu_squared in mus_squared){
  effs <- append(effs, efficiency(sqrt(mu_squared), variance, n))
}
plot(mus_squared, effs, type='l')
  
```

For fixed value of $\mu=10$ and $\sigma^2 = 4$, and for different values
of $n \in \{1, 2, 3, 4, \dots 200\}$, plot the graph of the efficiency
of $\hat{\theta}_\text{u}$. Thats is plot efficiency vs $n$ (the sample
size).

```{r}
mu = 10
variance = 4
effs = vector()
ns = seq(1,200)
for (n in ns){
  effs <- append(effs, efficiency(mu, variance, n))
}
plot(ns, effs, type='l')
 
```

# Population Distribution: $N(\mu, \sigma^2)$ and $\theta = \sigma^2$

Suppose $$S^2 = \frac{1}{n-1}\sum_{i=1}^n (X_i - \overline{X})^2$$ and
$$ \hat{\theta}_1 = S^2, \quad \hat{\theta}_2 = \frac{n-1}{n}S^2, \quad \hat{\theta}_3 = \frac{n-1}{n+1}S^2$$

For fixed value of $n=8$ and $\mu = 10$, and for different values of
$\sigma^2 \in [0, 50]$, plot the graphs of the mean square error
functions of the given estimators in a single plot. That is plot MSE vs
$\sigma^2$.

```{r}
x1 = vector()
y1 = vector()
for (i in 0:50){
  statistic <- var(rnorm(8, mean = 10, sd = sqrt(i)))
  b = (statistic - i)^2
  mse = 2*i^4/(8-1) + b
  x1 <- append(x1, i)
  y1 <- append(y1, mse)
}

x2 = vector()
y2 = vector()
for (i in 0:50){
  statistic <- ((8-1)/8)*var(rnorm(8, mean = 10, sd = sqrt(i)))
  b = (statistic - i)^2
  mse = ((8-1)^2 / 8^2)*(2*i^4/(8-1)) + b
  x2 <- append(x2, i)
  y2 <- append(y2, mse)
}

x3 = vector()
y3 = vector()
for (i in 0:50){
  statistic <- ((8-1)/(8+1))*var(rnorm(8, mean = 10, sd = sqrt(i)))
  b = (statistic - i)^2
  mse = ((8-1)^2 / (8+1)^2)*(2*i^4/(8-1)) + b
  x3 <- append(x3, i)
  y3 <- append(y3, mse)
}

plot(x1,y1,ylim=range(c(y1,y2,y3)),xlim=range(c(x1,x2,x3)), type="l",col="red",xlab="sigma^2",ylab="MSE")
lines(x2,y2,col="green")
lines(x3,y3,col="blue")
legend(x='topleft',legend=c("theta_1", "theta_2", "theta_3"), col=c("red","green","blue"), lty=1)




```

For fixed value of $\mu=10$ and $\sigma^2 = 4$, and for different values
of $n \in \{1, 2, 3, 4, \dots 200\}$, plot the graphs of the mean square
error functions of the three estimators in a single plot. That is plot
MSE vs $n$ (the sample size).

```{r}
x1 = vector()
y1 = vector()
for (i in 2:200){
  statistic <- var(rnorm(i, mean = 10, sd = 2))
  b = (statistic - 4)^2
  mse = 2*2^4/(i-1) + b
  x1 <- append(x1, i)
  y1 <- append(y1, mse)
}

x2 = vector()
y2 = vector()
for (i in 2:200){
  statistic <- ((i-1)/i)*var(rnorm(i, mean = 10, sd = 2))
  b = (statistic - 4)^2
  mse = ((i-1)^2 / i^2)*(2*2^4/(i-1)) + b
  x2 <- append(x2, i)
  y2 <- append(y2, mse)
}

x3 = vector()
y3 = vector()
for (i in 2:200){
  statistic <- ((i-1)/(i+1))*var(rnorm(i, mean = 10, sd = 2))
  b = (statistic - 4)^2
  mse = ((i-1)^2 / (i+1)^2)*(2*2^4/(i-1)) + b
  x3 <- append(x3, i)
  y3 <- append(y3, mse)
}

plot(x1,y1,ylim=range(c(y1,y2,y3)),xlim=range(c(x1,x2,x3)), lwd=1.2,type="l",col="red",xlab="n",ylab="MSE")
lines(x2,y2,col="green")
lines(x3,y3,col="blue")
legend(x='topright',legend=c("theta_1", "theta_2", "theta_3"), col=c("red","green","blue"), lty=1)

```
